{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import csv\n",
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import MeanShift\n",
    "from itertools import chain, combinations\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import Birch\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import re\n",
    "\n",
    "def decode(labels):\n",
    "    encoding = 'utf-8'\n",
    "\n",
    "    # decode from byte to string\n",
    "    labels = [str(x, encoding) for x in labels]\n",
    "    label_decoded = [x.replace('_', ' ') for x in labels]\n",
    "    \n",
    "    return label_decoded\n",
    "\n",
    "def get_labels_idx(keys, raw_labels):\n",
    "    # key: category\n",
    "    # value: index\n",
    "    \n",
    "    labels = {}\n",
    "\n",
    "    for i in range(len(raw_labels)):\n",
    "        for k in keys:\n",
    "            if k in raw_labels[i]:\n",
    "                if k not in labels:\n",
    "                    labels[k] = [i]\n",
    "                else:\n",
    "                    labels[k].append(i)\n",
    "                    \n",
    "    return labels\n",
    "\n",
    "def get_clusters_dict(labels):\n",
    "    # key: label\n",
    "    # value: indices of images\n",
    "    clusters = {}\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label not in clusters:\n",
    "            # The label is seen for first time, create a new list.\n",
    "            clusters[label] = [idx]\n",
    "        else:\n",
    "            clusters[label].append(idx)\n",
    "            \n",
    "    return clusters\n",
    "\n",
    "# Create label pairs\n",
    "\n",
    "def create_label_pairs(labels):\n",
    "    \n",
    "    label_pairs = {}\n",
    "    \n",
    "    for key, value in labels.items():\n",
    "        label_pairs[key] = list(itertools.combinations(value, 2)) \n",
    "        \n",
    "    label_pairs_concat = []\n",
    "\n",
    "    for key, value in label_pairs.items():\n",
    "        label_pairs_concat += value\n",
    "        \n",
    "    return label_pairs_concat\n",
    "\n",
    "# F-measure\n",
    "\n",
    "def evaluate(true_labels, cluster_labels):\n",
    "    \n",
    "    true_positive = list(set(true_labels).intersection(cluster_labels))\n",
    "    false_positive = list(set(cluster_labels) - set(true_labels))\n",
    "    false_negative = list(set(true_labels) - set(cluster_labels))\n",
    "\n",
    "    TP = len(true_positive)\n",
    "    FP = len(false_positive)\n",
    "    FN = len(false_negative)\n",
    "    \n",
    "    precision = round(TP/(TP+FP), 3)\n",
    "    \n",
    "    recall = round(TP/(TP+FN), 3)\n",
    "    \n",
    "    f_measure = round(2*((precision*recall)/(precision+recall)), 3)\n",
    "    \n",
    "    return f_measure, precision, recall\n",
    "    \n",
    "def evaluate_average(true_label_pairs, num_clusters, num_iter, algo):\n",
    "    \n",
    "    cumulative_f_measure = 0\n",
    "    cumulative_precision = 0\n",
    "    cumulative_recall = 0\n",
    "    cumulative_runtime = 0\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        if algo == \"Kmeans\":\n",
    "        \n",
    "            start = time.time()\n",
    "            \n",
    "            kmeans = KMeans(n_clusters = num_clusters).fit(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "            \n",
    "            k_means_clusters = get_clusters_dict(kmeans.labels_)\n",
    "            cluster_label_pairs = create_label_pairs(k_means_clusters)\n",
    "            \n",
    "        elif algo == \"HAC\":\n",
    "            start = time.time()\n",
    "            \n",
    "            clustering = AgglomerativeClustering(n_clusters=num_clusters, distance_threshold=None).fit(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "            \n",
    "            hac_clusters = get_clusters_dict(clustering.labels_)\n",
    "            cluster_label_pairs = create_label_pairs(hac_clusters)\n",
    "            \n",
    "        elif algo == \"Spectral\":\n",
    "            \n",
    "            start = time.time()\n",
    "\n",
    "            clustering = SpectralClustering(n_clusters=num_clusters).fit(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "\n",
    "            spectral_cluster = get_clusters_dict(clustering.labels_)\n",
    "            cluster_label_pairs = create_label_pairs(spectral_cluster)\n",
    "        \n",
    "        elif algo == \"GMM\":\n",
    "            start = time.time()\n",
    "\n",
    "            gmm_labels = GaussianMixture(n_components=num_clusters, init_params='kmeans').fit_predict(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "\n",
    "            gmm_clusters = get_clusters_dict(gmm_labels)\n",
    "\n",
    "            cluster_label_pairs = create_label_pairs(gmm_clusters)\n",
    "            \n",
    "        elif algo == \"Birch\":\n",
    "            \n",
    "            start = time.time()\n",
    "\n",
    "            brc = Birch(n_clusters=num_clusters, compute_labels=True).fit(X) \n",
    "\n",
    "            birch_labels = brc.predict(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "\n",
    "            birch_clusters = get_clusters_dict(birch_labels)\n",
    "\n",
    "            cluster_label_pairs = create_label_pairs(birch_clusters)\n",
    "            \n",
    "\n",
    "        f_measure, precision, recall = evaluate(true_label_pairs, cluster_label_pairs)\n",
    "            \n",
    "        cumulative_f_measure += f_measure\n",
    "        cumulative_precision += precision\n",
    "        cumulative_recall += recall\n",
    "        cumulative_runtime += runtime\n",
    "    \n",
    "    avg_f_measure = round(cumulative_f_measure/num_iter, 3)\n",
    "    avg_precision = round(cumulative_precision/num_iter, 3)\n",
    "    avg_recall = round(cumulative_recall/num_iter, 3)\n",
    "    avg_runtime = round(cumulative_runtime/num_iter, 3)\n",
    "            \n",
    "    print(\"{} Average F-Measure: {}\".format(algo, avg_f_measure))\n",
    "    print(\"{} Average Precision: {}\".format(algo, avg_precision))\n",
    "    print(\"{} Average Recall: {}\".format(algo, avg_recall))\n",
    "    print(\"{} Average Runtime: {}\".format(algo, avg_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 512)\n"
     ]
    }
   ],
   "source": [
    "# read in embeddings from ArcFace\n",
    "\n",
    "# Experiment 1\n",
    "arcface_embeddings = np.load(\"embeddings/experiment1/arcface/embeddings.npy\")\n",
    "arcface_raw_labels = np.load(\"embeddings/experiment1/arcface/names.npy\")\n",
    "\n",
    "# arcface_embeddings = np.load(\"embeddings/experiment1/facenet_arcface/faecnet_arcface_embeddings.npy\")\n",
    "# arcface_raw_labels = np.load(\"embeddings/experiment1/facenet_arcface/facenet_arcface_names.npy\")\n",
    "# Experiment 2\n",
    "# arcface_embeddings = np.load(\"embeddings/experiment2/arcface/ex2_arcface_embeddings.npy\")\n",
    "# arcface_raw_labels = np.load(\"embeddings/experiment2/arcface/ex2_arcface_names.npy\")\n",
    "# Experiment 3\n",
    "# arcface_embeddings = np.load(\"embeddings/experiment3/arcface/ex3_arcface_embeddings.npy\")\n",
    "# arcface_raw_labels = np.load(\"embeddings/experiment3/arcface/ex3_arcface_names.npy\")\n",
    "\n",
    "arcface_raw_labels = decode(arcface_raw_labels)\n",
    "arcface_raw_labels = [re.sub(\".png\", \"\", x) for x in arcface_raw_labels]\n",
    "arcface_raw_labels = [re.sub(\".jpg\", \"\", x) for x in arcface_raw_labels]\n",
    "\n",
    "print(arcface_embeddings.shape)\n",
    "#print(arcface_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 128)\n"
     ]
    }
   ],
   "source": [
    "# read in embeddings from dlib\n",
    "\n",
    "## Experiment 1\n",
    "dlib_embeddings = np.load(\"embeddings/experiment1/dlib/ex1_dlib_embeddings.npy\")\n",
    "dlib_raw_labels = np.load(\"embeddings/experiment1/dlib/ex1_dlib_names.npy\")\n",
    "\n",
    "## Experiment 2\n",
    "# dlib_embeddings = np.load(\"embeddings/experiment2/dlib/ex2_dlib_embeddings.npy\")\n",
    "# dlib_raw_labels = np.load(\"embeddings/experiment2/dlib/ex2_dlib_names.npy\")\n",
    "\n",
    "## Experiment 3\n",
    "# dlib_embeddings = np.load(\"embeddings/experiment3/dlib/ex3_dlib_embeddings.npy\")\n",
    "# dlib_raw_labels = np.load(\"embeddings/experiment3/dlib/ex3_dlib_names.npy\")\n",
    "\n",
    "dlib_raw_labels = [re.sub(\".png\", \"\", x) for x in dlib_raw_labels]\n",
    "dlib_raw_labels = [re.sub(\".jpg\", \"\", x) for x in dlib_raw_labels]\n",
    "dlib_raw_labels = [re.sub(\"_\", \" \", x) for x in dlib_raw_labels]\n",
    "\n",
    "print(dlib_embeddings.shape)\n",
    "\n",
    "#print(dlib_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 128)\n"
     ]
    }
   ],
   "source": [
    "# read in embeddings from Openface\n",
    "\n",
    "# Experiment 1\n",
    "data = list(csv.reader(open(\"embeddings/experiment1/openface/ex1_openface_reps.csv\")))\n",
    "label_s = list(csv.reader(open(\"embeddings/experiment1/openface/ex1_openface_labels.csv\")))\n",
    "\n",
    "# Experiment 2\n",
    "# data = list(csv.reader(open(\"embeddings/experiment2/openface/ex2_openface_reps.csv\")))\n",
    "# label_s = list(csv.reader(open(\"embeddings/experiment2/openface/ex2_openface_labels.csv\")))\n",
    "\n",
    "# Experiment 3\n",
    "# data = list(csv.reader(open(\"embeddings/experiment3/openface/ex3_openface_reps.csv\")))\n",
    "# label_s = list(csv.reader(open(\"embeddings/experiment3/openface/ex3_openface_labels.csv\")))\n",
    "\n",
    "\n",
    "openface_embeddings = np.asarray(data, dtype=float)\n",
    "openface_raw_labels = []\n",
    "\n",
    "for i in range(len(label_s)):\n",
    "    openface_raw_labels.append(label_s[i][1])\n",
    "\n",
    "# Experiment 1\n",
    "openface_raw_labels = [re.sub(\"./datasets/data1_aligned/\", \"\", x) for x in openface_raw_labels]\n",
    "# Experiment 2\n",
    "#openface_raw_labels = [re.sub(\"./datasets/ex2_openface_aligned/\", \"\", x) for x in openface_raw_labels]\n",
    "# Experiment 3\n",
    "#openface_raw_labels = [re.sub(\"./datasets/ex3_openface_aligned/\", \"\", x) for x in openface_raw_labels]\n",
    "\n",
    "openface_raw_labels = [re.sub(\"(?=\\/).*$\", \"\", x) for x in openface_raw_labels]\n",
    "openface_raw_labels = [re.sub(\"_\", \" \", x) for x in openface_raw_labels]\n",
    "\n",
    "print(openface_embeddings.shape)\n",
    "#print(openface_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 512)\n"
     ]
    }
   ],
   "source": [
    "# read in embeddings from FaceNet\",\n",
    "\n",
    "# Experiment 1\n",
    "facenet_embeddings = np.load(\"embeddings/experiment1/facenet/ex1_facenet_embeddings.npy\")\n",
    "label_strings = np.load(\"embeddings/experiment1/facenet/ex1_facenet_label_strings.npy\")\n",
    "# Experiment 2\n",
    "# facenet_embeddings = np.load(\"embeddings/experiment2/facenet/ex2_facenet_embeddings.npy\")\n",
    "# label_strings = np.load(\"embeddings/experiment2/facenet/ex2_facenet_label_strings.npy\")\n",
    "# # Experiment 3\n",
    "# facenet_embeddings = np.load(\"embeddings/experiment3/facenet/ex3_facenet_embeddings.npy\")\n",
    "# label_strings = np.load(\"embeddings/experiment3/facenet/ex3_facenet_label_strings.npy\")\n",
    "facenet_raw_labels = decode(label_strings)\n",
    "\n",
    "print(facenet_embeddings.shape)\n",
    "\n",
    "#print(facenet_raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting clustering and evaluation\n",
    "\n",
    "keys = [\"tennis\", \"basketball\", \"golf\", \"fighter\", \"soccer\"]\n",
    "\n",
    "\n",
    "# keys = [\"military officer\", \"politician\", \\\n",
    "#        \"manager\", \"soccer\", \"architect\", \\\n",
    "#        \"coach\", \"actor\", \"lawyer\", \"entrepreneur\", \"fighter\", \"musician\"]\n",
    "\n",
    "# Get label/index dictionary\n",
    "facenet_labels = get_labels_idx(keys, facenet_raw_labels)\n",
    "openface_labels = get_labels_idx(keys, openface_raw_labels)\n",
    "dlib_labels = get_labels_idx(keys, dlib_raw_labels)\n",
    "arcface_labels = get_labels_idx(keys, arcface_raw_labels)\n",
    "\n",
    "# Choose method\n",
    "feature_extraction_method = \"arcface\"\n",
    "\n",
    "if feature_extraction_method == \"openface\":\n",
    "\n",
    "    X = openface_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(openface_labels)\n",
    "    \n",
    "elif feature_extraction_method == \"facenet\":\n",
    "    \n",
    "    X = facenet_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(facenet_labels)\n",
    "\n",
    "elif feature_extraction_method == \"dlib\":\n",
    "    \n",
    "    X = dlib_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(dlib_labels)\n",
    "    \n",
    "elif feature_extraction_method == \"arcface\":\n",
    "    \n",
    "    X = arcface_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(arcface_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "golf\n",
      "558\n",
      "basketball\n",
      "225\n",
      "fighter\n",
      "560\n",
      "soccer\n",
      "735\n",
      "tennis\n",
      "102\n",
      "5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# c = 0\n",
    "# for key, value in facenet_labels.items():\n",
    "#     print(key)\n",
    "#     print(len(value))\n",
    "#     c+=len(value)\n",
    "    \n",
    "# print(c)\n",
    "\n",
    "# print(len(facenet_labels))\n",
    "\n",
    "# print()\n",
    "\n",
    "c = 0\n",
    "for key, value in arcface_labels.items():\n",
    "    print(key)\n",
    "    print(len(value))\n",
    "    c+=len(value)\n",
    "\n",
    "print(len(arcface_labels))\n",
    "\n",
    "print()\n",
    "\n",
    "# c = 0\n",
    "# for key, value in openface_labels.items():\n",
    "#     print(key)\n",
    "#     print(len(value))\n",
    "#     c+=len(value)\n",
    "    \n",
    "# print(c)\n",
    "\n",
    "# print(len(openface_labels))\n",
    "\n",
    "\n",
    "# print()\n",
    "\n",
    "# c = 0\n",
    "# for key, value in dlib_labels.items():\n",
    "#     print(key)\n",
    "#     print(len(value))\n",
    "#     c+=len(value)\n",
    "    \n",
    "# print(c)\n",
    "\n",
    "# print(len(dlib_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans Average F-Measure: 0.511\n",
      "Kmeans Average Precision: 0.582\n",
      "Kmeans Average Recall: 0.455\n",
      "Kmeans Average Runtime: 1.279\n",
      "\n",
      "HAC Average F-Measure: 0.413\n",
      "HAC Average Precision: 0.459\n",
      "HAC Average Recall: 0.376\n",
      "HAC Average Runtime: 0.719\n",
      "\n",
      "Spectral Average F-Measure: 0.465\n",
      "Spectral Average Precision: 0.531\n",
      "Spectral Average Recall: 0.414\n",
      "Spectral Average Runtime: 0.792\n",
      "\n",
      "GMM Average F-Measure: 0.513\n",
      "GMM Average Precision: 0.583\n",
      "GMM Average Recall: 0.459\n",
      "GMM Average Runtime: 0.914\n",
      "\n",
      "Birch Average F-Measure: 0.453\n",
      "Birch Average Precision: 0.473\n",
      "Birch Average Recall: 0.434\n",
      "Birch Average Runtime: 1.017\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 5\n",
    "num_iter = 10\n",
    "\n",
    "evaluate_average(true_label_pairs, num_clusters, num_iter, \"Kmeans\")\n",
    "print()\n",
    "evaluate_average(true_label_pairs, num_clusters, num_iter, \"HAC\")\n",
    "print()\n",
    "evaluate_average(true_label_pairs, num_clusters, num_iter, \"Spectral\")\n",
    "print()\n",
    "evaluate_average(true_label_pairs, num_clusters, num_iter, \"GMM\")\n",
    "print()\n",
    "evaluate_average(true_label_pairs, num_clusters, num_iter, \"Birch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means \n",
    "num_clusters = 5\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "kmeans = KMeans(n_clusters = num_clusters).fit(X)\n",
    "#print(kmeans.labels_)\n",
    "\n",
    "k_means_clusters = get_clusters_dict(kmeans.labels_)\n",
    "\n",
    "# print(labels)\n",
    "# print(\"\\n\")\n",
    "# print(k_means_clusters)\n",
    "\n",
    "kmeans_label_pairs = create_label_pairs(k_means_clusters)\n",
    "\n",
    "#F-measure\n",
    "\n",
    "print(evaluate(true_label_pairs, kmeans_label_pairs))\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print()\n",
    "\n",
    "# # Hierarchical Agglomerative Clustering\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# clustering = AgglomerativeClustering(n_clusters=num_clusters, distance_threshold=None).fit(X)\n",
    "# hac_clusters = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "# hac_label_pairs = create_label_pairs(hac_clusters)\n",
    "\n",
    "# f_measure(true_label_pairs, hac_label_pairs, \"HAC\")\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print()\n",
    "\n",
    "\n",
    "# # Spectral Clustering\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# clustering = SpectralClustering(n_clusters=num_clusters).fit(X)\n",
    "\n",
    "# spectral_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "# spectral_label_pairs = create_label_pairs(spectral_cluster)\n",
    "\n",
    "# f_measure(true_label_pairs, spectral_label_pairs, )\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print()\n",
    "\n",
    "# # Gaussian Mixture EM\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# gmm_labels = GaussianMixture(n_components=num_clusters, init_params='kmeans').fit_predict(X)\n",
    "\n",
    "# gmm_clusters = get_clusters_dict(gmm_labels)\n",
    "\n",
    "# gmm_label_pairs = create_label_pairs(gmm_clusters)\n",
    "\n",
    "# f_measure(true_label_pairs, gmm_label_pairs)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print()\n",
    "\n",
    "# # Birch\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# brc = Birch(n_clusters=num_clusters, compute_labels=True).fit(X) \n",
    "\n",
    "# birch_labels = brc.predict(X)\n",
    "\n",
    "# birch_clusters = get_clusters_dict(birch_labels)\n",
    "    \n",
    "# birch_label_pairs = create_label_pairs(birch_clusters)\n",
    "\n",
    "# f_measure(true_label_pairs, birch_label_pairs)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_average(true_label_pairs, num_clusters, num_iter, algo):\n",
    "    \n",
    "    cumulative_f_measure = 0\n",
    "    cumulative_precision = 0\n",
    "    cumulative_recall = 0\n",
    "    cumulative_runtime = 0\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        if algo == \"Kmeans\":\n",
    "        \n",
    "            start = time.time()\n",
    "            \n",
    "            kmeans = KMeans(n_clusters = num_clusters).fit(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "            \n",
    "            k_means_clusters = get_clusters_dict(kmeans.labels_)\n",
    "            cluster_label_pairs = create_label_pairs(k_means_clusters)\n",
    "            \n",
    "        elif algo == \"HAC\":\n",
    "            start = time.time()\n",
    "            \n",
    "            clustering = AgglomerativeClustering(n_clusters=num_clusters, distance_threshold=None).fit(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "            \n",
    "            hac_clusters = get_clusters_dict(clustering.labels_)\n",
    "            cluster_label_pairs = create_label_pairs(hac_clusters)\n",
    "            \n",
    "        elif algo == \"Spectral\":\n",
    "            \n",
    "            start = time.time()\n",
    "\n",
    "            clustering = SpectralClustering(n_clusters=num_clusters).fit(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "\n",
    "            spectral_cluster = get_clusters_dict(clustering.labels_)\n",
    "            cluster_label_pairs = create_label_pairs(spectral_cluster)\n",
    "        \n",
    "        elif algo == \"GMM\":\n",
    "            start = time.time()\n",
    "\n",
    "            gmm_labels = GaussianMixture(n_components=num_clusters, init_params='kmeans').fit_predict(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "\n",
    "            gmm_clusters = get_clusters_dict(gmm_labels)\n",
    "\n",
    "            cluster_label_pairs = create_label_pairs(gmm_clusters)\n",
    "            \n",
    "        elif algo == \"Birch\":\n",
    "            \n",
    "            start = time.time()\n",
    "\n",
    "            brc = Birch(n_clusters=num_clusters, compute_labels=True).fit(X) \n",
    "\n",
    "            birch_labels = brc.predict(X)\n",
    "            \n",
    "            runtime = round((time.time() - start), 3)\n",
    "\n",
    "            birch_clusters = get_clusters_dict(birch_labels)\n",
    "\n",
    "            cluster_label_pairs = create_label_pairs(birch_clusters)\n",
    "            \n",
    "\n",
    "        f_measure, precision, recall = evaluate(true_label_pairs, cluster_label_pairs)\n",
    "            \n",
    "        cumulative_f_measure += f_measure\n",
    "        cumulative_precision += precision\n",
    "        cumulative_recall += recall\n",
    "        cumulative_runtime += runtime\n",
    "    \n",
    "    avg_f_measure = round(cumulative_f_measure/num_iter, 3)\n",
    "    avg_precision = round(cumulative_precision/num_iter, 3)\n",
    "    avg_recall = round(cumulative_recall/num_iter, 3)\n",
    "    avg_runtime = round(cumulative_runtime/num_iter, 3)\n",
    "            \n",
    "    print(\"{} Average F-Measure: {}\".format(algo, avg_f_measure))\n",
    "    print(\"{} Average Precision: {}\".format(algo, avg_precision))\n",
    "    print(\"{} Average Recall: {}\".format(algo, avg_recall))\n",
    "    print(\"{} Average Runtime: {}\".format(algo, avg_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find error pairs\n",
    "\n",
    "true_positive = list(set(true_label_pairs).intersection(hac_label_pairs))\n",
    "false_positive = list(set(hac_label_pairs) - set(true_label_pairs))\n",
    "false_negative = list(set(true_label_pairs) - set(hac_label_pairs))\n",
    "\n",
    "print(false_positive[:100])\n",
    "\n",
    "f = false_positive[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in f:\n",
    "    print(facenet_raw_labels[pair[0]])\n",
    "    print(facenet_raw_labels[pair[1]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DBSCAN\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# clustering = DBSCAN(eps=1, min_samples= 3).fit(X)\n",
    "# DBSCAN_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "# print(clustering.labels_)\n",
    "# print(\"\\n\")\n",
    "# print(len(DBSCAN_cluster))\n",
    "# print(\"\\n\")\n",
    "# DBSCAN_label_pairs = create_label_pairs(DBSCAN_cluster)\n",
    "\n",
    "# f_measure(true_label_pairs, DBSCAN_label_pairs, \"DBSCAN\")\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print()\n",
    "\n",
    "# # Affinity Propagation\n",
    "# start_time = time.time()\n",
    "\n",
    "# clustering = AffinityPropagation().fit(X)\n",
    "\n",
    "# ap_clusters = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "# print(len(ap_clusters))\n",
    "\n",
    "# ap_label_pairs = create_label_pairs(ap_clusters)\n",
    "\n",
    "# f_measure(true_label_pairs, ap_label_pairs, \"Affinity Porpagation\")\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print()\n",
    "\n",
    "# # Mean shift\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# clustering = MeanShift(bandwidth=1).fit(X)\n",
    "\n",
    "# mean_shift_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "# print(clustering.labels_)\n",
    "# print(\"\\n\")\n",
    "# print(len(mean_shift_cluster))\n",
    "# print(\"\\n\")\n",
    "# mean_shift_label_pairs = create_label_pairs(mean_shift_cluster)\n",
    "\n",
    "# f_measure(true_label_pairs, mean_shift_label_pairs, \"Mean Shift\")\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# reduced_centroids = pca.fit_transform(kmeans.cluster_centers_)\n",
    "\n",
    "# colors = [\"#ffe119\", \"#f032e6\", \"#9A6324\", \"#3cb44b\", \"#e6194B\", \"#f58231\", \"#ffe119\", \"#469990\", \"#42d4f4\", \"#4363d8\", \"#911eb4\"]\n",
    "\n",
    "# # plt.scatter(X[:,0], X[:,1], s=5)\n",
    "\n",
    "# for i in kmeans.labels_:\n",
    "#     color = colors[i]\n",
    "#     for feature in principalComponents[kmeans.labels_ == i]:\n",
    "#         plt.scatter(feature[0], feature[1], marker=\"x\", color=color, s=5, linewidths=5)\n",
    "#     plt.scatter(reduced_centroids[i][0], reduced_centroids[i][1], marker=\"o\", color=color, edgecolors='black',  s=30, linewidths=1)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
