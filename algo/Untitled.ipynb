{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 64,
=======
   "execution_count": 384,
>>>>>>> dc0a5632a0825909dc8ba1b05279b93eb075e0cb
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import csv\n",
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import MeanShift\n",
    "from itertools import chain, combinations\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import Birch\n",
    "import itertools\n",
    "import time\n",
<<<<<<< HEAD
    "from sklearn.cluster import AffinityPropagation\n",
    "import re\n",
=======
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2180\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.round(np.load(\"embeddings/data1/embeddings.npy\"), decimals=6)\n",
    "t_labels = np.load(\"embeddings/data1/labels.npy\")\n",
    "label_strings = np.load(\"embeddings/data1/label_strings.npy\")\n",
>>>>>>> dc0a5632a0825909dc8ba1b05279b93eb075e0cb
    "\n",
    "def get_labels_idx(keys, labels_string):\n",
    "    # key: category\n",
    "    # value: tuple of name and index, e.g. ('Andy Murray', 0)\n",
    "    labels = {k: [] for k in keys}\n",
    "\n",
    "    for i in range(len(labels_string)):\n",
    "        for k in keys:\n",
    "            if k in labels_string[i]:\n",
    "                name = labels_string[i].replace(k, \"\")\n",
    "                labels[k].append(i)\n",
    "    return labels\n",
    "\n",
<<<<<<< HEAD
=======
    "print(len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to assign image indices to each category\n",
    "\n",
    "keys = [\"tennis\", \"basketball\", \"golf\", \"fighter\", \"soccer\"]\n",
    "\n",
    "# key: category\n",
    "# value: indices of the images\n",
    "# e.g. {'tennis': [41, 54, ...], 'basketball': [...], 'golf': [...], 'fighter': [...], 'soccer': [...]}\n",
    "labels = {k: [] for k in keys}\n",
    "\n",
    "# For each file name of the images\n",
    "for i in range(len(label_decoded)):\n",
    "    # For each category\n",
    "    for k in keys:\n",
    "        # If the category name is in the file name\n",
    "        if k in label_decoded[i]:\n",
    "            # Replace the category by an empty string\n",
    "            name = label_decoded[i].replace(k, \"\")\n",
    "            # Append the indices of the file names to each category\n",
    "            labels[k].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# reduced_centroids = pca.fit_transform(kmeans.cluster_centers_)\n",
    "\n",
    "# colors = [\"#ffe119\", \"#f032e6\", \"#9A6324\", \"#3cb44b\", \"#e6194B\", \"#f58231\", \"#ffe119\", \"#469990\", \"#42d4f4\", \"#4363d8\", \"#911eb4\"]\n",
    "\n",
    "# # plt.scatter(X[:,0], X[:,1], s=5)\n",
    "\n",
    "# for i in kmeans.labels_:\n",
    "#     color = colors[i]\n",
    "#     for feature in principalComponents[kmeans.labels_ == i]:\n",
    "#         plt.scatter(feature[0], feature[1], marker=\"x\", color=color, s=5, linewidths=5)\n",
    "#     plt.scatter(reduced_centroids[i][0], reduced_centroids[i][1], marker=\"o\", color=color, edgecolors='black',  s=30, linewidths=1)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> dc0a5632a0825909dc8ba1b05279b93eb075e0cb
    "def get_clusters_dict(labels):\n",
    "    # key: label\n",
    "    # value: indices of images\n",
    "    clusters = {}\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label not in clusters:\n",
    "            # The label is seen for first time, create a new list.\n",
    "            clusters[label] = [idx]\n",
    "        else:\n",
    "            clusters[label].append(idx)\n",
    "            \n",
    "    return clusters\n",
    "\n",
    "# Create label pairs\n",
    "\n",
    "def create_label_pairs(labels):\n",
    "    \n",
    "    label_pairs = {}\n",
    "    \n",
    "    for key, value in labels.items():\n",
    "        label_pairs[key] = list(itertools.combinations(value, 2)) \n",
    "        \n",
    "    label_pairs_concat = []\n",
    "\n",
    "    for key, value in label_pairs.items():\n",
    "        label_pairs_concat += value\n",
    "        \n",
    "    return label_pairs_concat\n",
    "\n",
    "# F-measure\n",
    "\n",
    "def f_measure(true_labels, cluster_labels, algo):\n",
    "    \n",
    "    true_positive = list(set(true_labels).intersection(cluster_labels))\n",
    "    false_positive = list(set(cluster_labels) - set(true_labels))\n",
    "    false_negative = list(set(true_labels) - set(cluster_labels))\n",
    "\n",
    "    TP = len(true_positive)\n",
    "    FP = len(false_positive)\n",
    "    FN = len(false_negative)\n",
    "\n",
    "    print(\"{} Number of False Positives: {}\".format(algo, FP))\n",
    "    \n",
    "    precision = round(TP/(TP+FP), 3)\n",
    "    print(\"{} Precision: {}\".format(algo, precision))\n",
    "    recall = round(TP/(TP+FN), 3)\n",
    "    print(\"{} Recall: {}\".format(algo, recall))\n",
    "    f_measure = round(2*((precision*recall)/(precision+recall)), 3)\n",
    "    print(\"{} F-Measure: {}\".format(algo, f_measure))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 83,
=======
   "execution_count": 391,
>>>>>>> dc0a5632a0825909dc8ba1b05279b93eb075e0cb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(2180, 128)\n"
=======
      "K-means Number of False Positives: 258878\n",
      "K-means Precision: 0.52\n",
      "K-means Recall: 0.46\n",
      "K-means F-Measure: 0.49\n",
      "--- 2.4511992931365967 seconds ---\n"
>>>>>>> dc0a5632a0825909dc8ba1b05279b93eb075e0cb
     ]
    }
   ],
   "source": [
    "# read in embeddings from Openface\n",
    "\n",
<<<<<<< HEAD
    "data = list(csv.reader(open(\"embeddings/data1_openface_embeddings/reps.csv\")))\n",
    "label_s = list(csv.reader(open(\"embeddings/data1_openface_embeddings/labels.csv\")))\n",
=======
    "kmeans = KMeans(n_clusters = num_clusters).fit(X)\n",
>>>>>>> dc0a5632a0825909dc8ba1b05279b93eb075e0cb
    "\n",
    "openface_embeddings = np.asarray(data, dtype=float)\n",
    "openface_raw_labels = []\n",
    "\n",
<<<<<<< HEAD
    "for i in range(len(label_s)):\n",
    "    openface_raw_labels.append(label_s[i][1])\n",
    "\n",
    "openface_raw_labels = [re.sub(\"./datasets/data1_aligned/\", \"\", x) for x in openface_raw_labels]\n",
    "openface_raw_labels = [re.sub(\"(?=\\/).*$\", \"\", x) for x in openface_raw_labels]\n",
    "\n",
    "print(openface_embeddings.shape)"
=======
    "true_label_pairs = create_label_pairs(labels)\n",
    "kmeans_label_pairs = create_label_pairs(k_means_clusters)\n",
    "\n",
    "#F-measure\n",
    "\n",
    "f_measure(true_label_pairs, kmeans_label_pairs, \"K-means\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
>>>>>>> dc0a5632a0825909dc8ba1b05279b93eb075e0cb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 512)\n"
     ]
    }
   ],
   "source": [
    "# read in embeddings from FaceNet\n",
    "\n",
    "facenet_embeddings = np.load(\"embeddings/data1/embeddings.npy\")\n",
    "#t_labels = np.load(\"embeddings/data1/labels.npy\")\n",
    "label_strings = np.load(\"embeddings/data1/label_strings.npy\")\n",
    "\n",
    "encoding = 'utf-8'\n",
    "# decode from byte to string\n",
    "l = [str(x, encoding) for x in label_strings]\n",
    "label_decoded = [x.replace('_', ' ') for x in l]\n",
    "\n",
    "print(facenet_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting clustering and evaluation\n",
    "\n",
    "keys = [\"tennis\", \"basketball\", \"golf\", \"fighter\", \"soccer\"]\n",
    "\n",
    "# Get label/index dictionary\n",
    "facenet_labels = get_labels_idx(keys, label_decoded)\n",
    "openface_labels = get_labels_idx(keys, openface_raw_labels)\n",
    "\n",
    "## Choose method\n",
    "feature_extraction_method = \"openface\"\n",
    "\n",
    "if feature_extraction_method == \"openface\":\n",
    "\n",
    "    X = openface_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(openface_labels)\n",
    "    \n",
    "elif feature_extraction_method == \"facenet\":\n",
    "    \n",
    "    X = facenet_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(facenet_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means Number of False Positives: 315014\n",
      "K-means Precision: 0.409\n",
      "K-means Recall: 0.357\n",
      "K-means F-Measure: 0.381\n",
      "--- 0.8548526763916016 seconds ---\n",
      "\n",
      "HAC Number of False Positives: 438934\n",
      "HAC Precision: 0.368\n",
      "HAC Recall: 0.417\n",
      "HAC F-Measure: 0.391\n",
      "--- 0.9472081661224365 seconds ---\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "DBSCAN Number of False Positives: 1763091\n",
      "DBSCAN Precision: 0.258\n",
      "DBSCAN Recall: 1.0\n",
      "DBSCAN F-Measure: 0.41\n",
      "--- 3.2526118755340576 seconds ---\n",
      "\n",
      "Spectral Number of False Positives: 362277\n",
      "Spectral Precision: 0.359\n",
      "Spectral Recall: 0.332\n",
      "Spectral F-Measure: 0.345\n",
      "--- 1.4133806228637695 seconds ---\n",
      "\n",
      "GMM Number of False Positives: 316854\n",
      "GMM Precision: 0.406\n",
      "GMM Recall: 0.354\n",
      "GMM F-Measure: 0.378\n",
      "--- 0.951854944229126 seconds ---\n",
      "\n",
      "Birch Number of False Positives: 386987\n",
      "Birch Precision: 0.345\n",
      "Birch Recall: 0.332\n",
      "Birch F-Measure: 0.338\n",
      "--- 0.8125154972076416 seconds ---\n",
      "\n",
      "127\n",
      "Affinity Porpagation Number of False Positives: 11801\n",
      "Affinity Porpagation Precision: 0.452\n",
      "Affinity Porpagation Recall: 0.016\n",
      "Affinity Porpagation F-Measure: 0.031\n",
      "--- 3.9913315773010254 seconds ---\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "Mean Shift Number of False Positives: 1763091\n",
      "Mean Shift Precision: 0.258\n",
      "Mean Shift Recall: 1.0\n",
      "Mean Shift F-Measure: 0.41\n",
      "--- 32.74966835975647 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# K-means \n",
    "num_clusters = 5\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "kmeans = KMeans(n_clusters = num_clusters).fit(X)\n",
    "#print(kmeans.labels_)\n",
    "\n",
    "k_means_clusters = get_clusters_dict(kmeans.labels_)\n",
    "\n",
    "# print(labels)\n",
    "# print(\"\\n\")\n",
    "# print(k_means_clusters)\n",
    "\n",
    "kmeans_label_pairs = create_label_pairs(k_means_clusters)\n",
    "\n",
    "#F-measure\n",
    "\n",
    "f_measure(true_label_pairs, kmeans_label_pairs, \"K-means\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Hierarchical Agglomerative Clustering\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=5, distance_threshold=None).fit(X)\n",
    "hac_clusters = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "hac_label_pairs = create_label_pairs(hac_clusters)\n",
    "\n",
    "f_measure(true_label_pairs, hac_label_pairs, \"HAC\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# DBSCAN\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = DBSCAN(eps=1, min_samples= 3).fit(X)\n",
    "DBSCAN_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "print(clustering.labels_)\n",
    "print(\"\\n\")\n",
    "print(len(DBSCAN_cluster))\n",
    "print(\"\\n\")\n",
    "DBSCAN_label_pairs = create_label_pairs(DBSCAN_cluster)\n",
    "\n",
    "f_measure(true_label_pairs, DBSCAN_label_pairs, \"DBSCAN\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Spectral Clustering\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = SpectralClustering(n_clusters=5).fit(X)\n",
    "\n",
    "spectral_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "spectral_label_pairs = create_label_pairs(spectral_cluster)\n",
    "\n",
    "f_measure(true_label_pairs, spectral_label_pairs, \"Spectral\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Gaussian Mixture EM\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gmm_labels = GaussianMixture(n_components=5, init_params='kmeans').fit_predict(X)\n",
    "\n",
    "gmm_clusters = get_clusters_dict(gmm_labels)\n",
    "\n",
    "gmm_label_pairs = create_label_pairs(gmm_clusters)\n",
    "\n",
    "f_measure(true_label_pairs, gmm_label_pairs, \"GMM\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Birch\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "brc = Birch(n_clusters=5, threshold=0.58, compute_labels=True).fit(X) \n",
    "\n",
    "birch_labels = brc.predict(X)\n",
    "\n",
    "birch_clusters = get_clusters_dict(birch_labels)\n",
    "\n",
    "birch_label_pairs = create_label_pairs(birch_clusters)\n",
    "\n",
    "f_measure(true_label_pairs, birch_label_pairs, \"Birch\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Affinity Propagation\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = AffinityPropagation().fit(X)\n",
    "\n",
    "ap_clusters = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "print(len(ap_clusters))\n",
    "\n",
    "ap_label_pairs = create_label_pairs(ap_clusters)\n",
    "\n",
    "f_measure(true_label_pairs, ap_label_pairs, \"Affinity Porpagation\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Mean shift\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = MeanShift(bandwidth=1).fit(X)\n",
    "\n",
    "mean_shift_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "print(clustering.labels_)\n",
    "print(\"\\n\")\n",
    "print(len(mean_shift_cluster))\n",
    "print(\"\\n\")\n",
    "mean_shift_label_pairs = create_label_pairs(mean_shift_cluster)\n",
    "\n",
    "f_measure(true_label_pairs, mean_shift_label_pairs, \"Mean Shift\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 9), (5, 31), (3, 35), (27, 46), (30, 41), (28, 41), (3, 24), (0, 32), (25, 43), (44, 45), (9, 21), (24, 27), (39, 45), (15, 30), (2, 42), (25, 26), (32, 38), (7, 19), (5, 47), (33, 39), (16, 25), (5, 11), (29, 30), (8, 21), (6, 23), (7, 22), (17, 39), (16, 41), (37, 44), (27, 49), (39, 42), (2, 37), (9, 19), (7, 8), (5, 40), (0, 27), (7, 21), (12, 27), (33, 45), (34, 42), (8, 9), (24, 46), (25, 30), (20, 21), (12, 24), (1, 5), (41, 43), (17, 45), (3, 27), (46, 49), (9, 20), (15, 25), (39, 44), (7, 18), (30, 43), (26, 30), (18, 21), (34, 37), (12, 35), (5, 10), (12, 46), (0, 46), (14, 25), (4, 17), (27, 38), (9, 23), (32, 49), (6, 20), (4, 44), (3, 49), (12, 32), (5, 13), (3, 38), (9, 18), (4, 33), (7, 20), (5, 36), (42, 44), (19, 21), (27, 32), (2, 39), (25, 29), (6, 18), (16, 30), (21, 23), (0, 12), (15, 41), (35, 49), (38, 46), (6, 8), (3, 32), (33, 37), (35, 38), (33, 42), (14, 41), (2, 4), (14, 30), (9, 22), (6, 21), (2, 45), (0, 3), (34, 39), (17, 37), (28, 30), (17, 42), (37, 39), (26, 41), (6, 22), (4, 34), (7, 23), (5, 48), (12, 38), (24, 35), (12, 49), (27, 35), (25, 28), (7, 9), (6, 19), (4, 39), (21, 22), (29, 41), (34, 45), (0, 35), (24, 32), (3, 46)]\n"
     ]
    }
   ],
   "source": [
    "# Find error pairs\n",
    "\n",
    "true_positive = list(set(true_label_pairs).intersection(hac_label_pairs))\n",
    "false_positive = list(set(hac_label_pairs) - set(true_label_pairs))\n",
    "false_negative = list(set(true_label_pairs) - set(hac_label_pairs))\n",
    "\n",
    "print(false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyeon Chung tennis\n",
      "Radu Albot tennis\n"
     ]
    }
   ],
   "source": [
    "print(label_decoded[27])\n",
    "print(label_decoded[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# reduced_centroids = pca.fit_transform(kmeans.cluster_centers_)\n",
    "\n",
    "# colors = [\"#ffe119\", \"#f032e6\", \"#9A6324\", \"#3cb44b\", \"#e6194B\", \"#f58231\", \"#ffe119\", \"#469990\", \"#42d4f4\", \"#4363d8\", \"#911eb4\"]\n",
    "\n",
    "# # plt.scatter(X[:,0], X[:,1], s=5)\n",
    "\n",
    "# for i in kmeans.labels_:\n",
    "#     color = colors[i]\n",
    "#     for feature in principalComponents[kmeans.labels_ == i]:\n",
    "#         plt.scatter(feature[0], feature[1], marker=\"x\", color=color, s=5, linewidths=5)\n",
    "#     plt.scatter(reduced_centroids[i][0], reduced_centroids[i][1], marker=\"o\", color=color, edgecolors='black',  s=30, linewidths=1)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
