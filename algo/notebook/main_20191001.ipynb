{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import csv\n",
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import MeanShift\n",
    "from itertools import chain, combinations\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import Birch\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "def get_labels_idx(keys, labels_string):\n",
    "    # key: category\n",
    "    # value: tuple of name and index, e.g. ('Andy Murray', 0)\n",
    "    labels = {k: [] for k in keys}\n",
    "\n",
    "    for i in range(len(labels_string)):\n",
    "        for k in keys:\n",
    "            if k in labels_string[i]:\n",
    "                name = labels_string[i].replace(k, \"\")\n",
    "                labels[k].append(i)\n",
    "    return labels\n",
    "\n",
    "def get_clusters_dict(labels):\n",
    "    # key: label\n",
    "    # value: indices of images\n",
    "    clusters = {}\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label not in clusters:\n",
    "            # The label is seen for first time, create a new list.\n",
    "            clusters[label] = [idx]\n",
    "        else:\n",
    "            clusters[label].append(idx)\n",
    "            \n",
    "    return clusters\n",
    "\n",
    "# Create label pairs\n",
    "\n",
    "def create_label_pairs(labels):\n",
    "    \n",
    "    label_pairs = {}\n",
    "    \n",
    "    for key, value in labels.items():\n",
    "        label_pairs[key] = list(itertools.combinations(value, 2)) \n",
    "        \n",
    "    label_pairs_concat = []\n",
    "\n",
    "    for key, value in label_pairs.items():\n",
    "        label_pairs_concat += value\n",
    "        \n",
    "    return label_pairs_concat\n",
    "\n",
    "# F-measure\n",
    "\n",
    "def f_measure(true_labels, cluster_labels, algo):\n",
    "    \n",
    "    true_positive = list(set(true_labels).intersection(cluster_labels))\n",
    "    false_positive = list(set(cluster_labels) - set(true_labels))\n",
    "    false_negative = list(set(true_labels) - set(cluster_labels))\n",
    "\n",
    "    TP = len(true_positive)\n",
    "    FP = len(false_positive)\n",
    "    FN = len(false_negative)\n",
    "    \n",
    "    precision = round(TP/(TP+FP), 2)\n",
    "    \n",
    "    recall = round(TP/(TP+FN), 2)\n",
    "    \n",
    "    f_measure = round(2*((precision*recall)/(precision+recall)), 2)\n",
    "    \n",
    "    print(\"{} F-Measure: {}\".format(algo, f_measure))\n",
    "    print(\"{} Precision: {}\".format(algo, precision))\n",
    "    print(\"{} Recall: {}\".format(algo, recall))\n",
    "    print(\"{} Number of False Positives: {}\".format(algo, FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2180\n"
     ]
    }
   ],
   "source": [
    "e = np.load(\"data1_embeddings.npy\")\n",
    "n = np.load(\"data1_names.npy\")\n",
    "\n",
    "print(len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in embeddings from Openface\n",
    "\n",
    "data = list(csv.reader(open(\"embeddings/data1_mtcnn_160_embeddings/reps.csv\")))\n",
    "label_s = list(csv.reader(open(\"embeddings/data1_mtcnn_160_embeddings/labels.csv\")))\n",
    "\n",
    "openface_embeddings = np.asarray(data, dtype=float)\n",
    "openface_raw_labels = []\n",
    "\n",
    "for i in range(len(label_s)):\n",
    "    openface_raw_labels.append(label_s[i][1])\n",
    "\n",
    "openface_raw_labels = [re.sub(\"./datasets/data1_mtcnnpy_160/\", \"\", x) for x in openface_raw_labels]\n",
    "openface_raw_labels = [re.sub(\"(?=\\/).*$\", \"\", x) for x in openface_raw_labels]\n",
    "\n",
    "print(openface_embeddings.shape)\n",
    "print(openface_raw_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = [item for item, count in Counter(dlib_raw_labels).items() if count > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Steve_Lowery_golf', 'Renan_Barao_fighter', 'Brett_Stegmaier_golf', 'Juli√°n_Etulain_golf', 'Abraham_Ancer_golf', 'Mike_Weir_golf', 'Jin_Jeong_golf', 'Donald_Constable_golf', 'Scott_Brown_golf', 'Michael_Allen_golf', 'Kevin_Na_golf', 'Justin_Jones_fighter']\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 301]\n",
      "[333, 334]\n",
      "[381, 382]\n",
      "[406, 407]\n",
      "[442, 443]\n",
      "[868, 869]\n",
      "[932, 933]\n",
      "[943, 944]\n",
      "[948, 949]\n",
      "[963, 964]\n",
      "[1667, 1668]\n",
      "[1719, 1720]\n",
      "2192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j in range(len(a)):\n",
    "    indices = [i for i, x in enumerate(dlib_raw_labels) if x == a[j]]\n",
    "    \n",
    "    print(indices)\n",
    "    \n",
    "d = [301, 334, 382, 407, 443, 869, 933, 944, 949, 964, 1668, 1720]\n",
    "\n",
    "print(len(dlib_raw_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in embeddings from FaceNet\",\n",
    "\n",
    "facenet_embeddings = np.load(\"embeddings/data1/embeddings.npy\")\n",
    "t_labels = np.load(\"embeddings/data1/labels.npy\")\n",
    "label_strings = np.load(\"embeddings/data1/label_strings.npy\")\n",
    "\n",
    "encoding = 'utf-8'\n",
    "\n",
    "# decode from byte to string\n",
    "l = [str(x, encoding) for x in label_strings]\n",
    "label_decoded = [x.replace('_', ' ') for x in l]\n",
    "\n",
    "print(facenet_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting clustering and evaluation\n",
    "\n",
    "keys = [\"tennis\", \"basketball\", \"golf\", \"fighter\", \"soccer\"]\n",
    "\n",
    "# Get label/index dictionary\n",
    "facenet_labels = get_labels_idx(keys, label_decoded)\n",
    "openface_labels = get_labels_idx(keys, openface_raw_labels)\n",
    "dlib_labels = get_labels_idx(keys, dlib_raw_labels)\n",
    "\n",
    "for k, v in openface_labels.items():\n",
    "    print(k)\n",
    "    print(len(v))\n",
    "\n",
    "## Choose method\n",
    "feature_extraction_method = \"dlib\"\n",
    "\n",
    "if feature_extraction_method == \"openface\":\n",
    "\n",
    "    X = openface_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(openface_labels)\n",
    "    \n",
    "elif feature_extraction_method == \"facenet\":\n",
    "    \n",
    "    X = facenet_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(facenet_labels)\n",
    "\n",
    "elif feature_extraction_method == \"dlib\":\n",
    "    \n",
    "    X = dlib_embeddings\n",
    "    # Create ground truth pairs for evaulation\n",
    "    true_label_pairs = create_label_pairs(dlib_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means \n",
    "num_clusters = 5\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "kmeans = KMeans(n_clusters = num_clusters).fit(X)\n",
    "#print(kmeans.labels_)\n",
    "\n",
    "k_means_clusters = get_clusters_dict(kmeans.labels_)\n",
    "\n",
    "# print(labels)\n",
    "# print(\"\\n\")\n",
    "# print(k_means_clusters)\n",
    "\n",
    "kmeans_label_pairs = create_label_pairs(k_means_clusters)\n",
    "\n",
    "#F-measure\n",
    "\n",
    "f_measure(true_label_pairs, kmeans_label_pairs, \"K-means\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Hierarchical Agglomerative Clustering\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=5, distance_threshold=None).fit(X)\n",
    "hac_clusters = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "hac_label_pairs = create_label_pairs(hac_clusters)\n",
    "\n",
    "f_measure(true_label_pairs, hac_label_pairs, \"HAC\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# DBSCAN\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = DBSCAN(eps=1, min_samples= 3).fit(X)\n",
    "DBSCAN_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "print(clustering.labels_)\n",
    "print(\"\\n\")\n",
    "print(len(DBSCAN_cluster))\n",
    "print(\"\\n\")\n",
    "DBSCAN_label_pairs = create_label_pairs(DBSCAN_cluster)\n",
    "\n",
    "f_measure(true_label_pairs, DBSCAN_label_pairs, \"DBSCAN\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Spectral Clustering\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = SpectralClustering(n_clusters=5).fit(X)\n",
    "\n",
    "spectral_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "spectral_label_pairs = create_label_pairs(spectral_cluster)\n",
    "\n",
    "f_measure(true_label_pairs, spectral_label_pairs, \"Spectral\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Gaussian Mixture EM\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gmm_labels = GaussianMixture(n_components=5, init_params='kmeans').fit_predict(X)\n",
    "\n",
    "gmm_clusters = get_clusters_dict(gmm_labels)\n",
    "\n",
    "gmm_label_pairs = create_label_pairs(gmm_clusters)\n",
    "\n",
    "f_measure(true_label_pairs, gmm_label_pairs, \"GMM\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Birch\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "brc = Birch(n_clusters=5, threshold=0.58, compute_labels=True).fit(X) \n",
    "\n",
    "birch_labels = brc.predict(X)\n",
    "\n",
    "birch_clusters = get_clusters_dict(birch_labels)\n",
    "\n",
    "birch_label_pairs = create_label_pairs(birch_clusters)\n",
    "\n",
    "f_measure(true_label_pairs, birch_label_pairs, \"Birch\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Affinity Propagation\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = AffinityPropagation().fit(X)\n",
    "\n",
    "ap_clusters = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "print(len(ap_clusters))\n",
    "\n",
    "ap_label_pairs = create_label_pairs(ap_clusters)\n",
    "\n",
    "f_measure(true_label_pairs, ap_label_pairs, \"Affinity Porpagation\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print()\n",
    "\n",
    "# Mean shift\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clustering = MeanShift(bandwidth=1).fit(X)\n",
    "\n",
    "mean_shift_cluster = get_clusters_dict(clustering.labels_)\n",
    "\n",
    "print(clustering.labels_)\n",
    "print(\"\\n\")\n",
    "print(len(mean_shift_cluster))\n",
    "print(\"\\n\")\n",
    "mean_shift_label_pairs = create_label_pairs(mean_shift_cluster)\n",
    "\n",
    "f_measure(true_label_pairs, mean_shift_label_pairs, \"Mean Shift\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find error pairs\n",
    "\n",
    "true_positive = list(set(true_label_pairs).intersection(hac_label_pairs))\n",
    "false_positive = list(set(hac_label_pairs) - set(true_label_pairs))\n",
    "false_negative = list(set(true_label_pairs) - set(hac_label_pairs))\n",
    "\n",
    "print(false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_decoded[27])\n",
    "print(label_decoded[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# reduced_centroids = pca.fit_transform(kmeans.cluster_centers_)\n",
    "\n",
    "# colors = [\"#ffe119\", \"#f032e6\", \"#9A6324\", \"#3cb44b\", \"#e6194B\", \"#f58231\", \"#ffe119\", \"#469990\", \"#42d4f4\", \"#4363d8\", \"#911eb4\"]\n",
    "\n",
    "# # plt.scatter(X[:,0], X[:,1], s=5)\n",
    "\n",
    "# for i in kmeans.labels_:\n",
    "#     color = colors[i]\n",
    "#     for feature in principalComponents[kmeans.labels_ == i]:\n",
    "#         plt.scatter(feature[0], feature[1], marker=\"x\", color=color, s=5, linewidths=5)\n",
    "#     plt.scatter(reduced_centroids[i][0], reduced_centroids[i][1], marker=\"o\", color=color, edgecolors='black',  s=30, linewidths=1)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
